{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load(\"oxford_flowers102\", with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info.features[\"label\"].names)\n",
    "print(info.features['label'].num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, (image, label) in enumerate(train_dataset.take(5)): \n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(image.numpy())\n",
    "    print(info.features[\"label\"].names[label.numpy()])\n",
    "    plt.title(f\"Class: {label.numpy()}\\n{info.features['label'].names[label.numpy()]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = info.features[\"label\"].names\n",
    "label_mapping = {i: name for i, name in enumerate(class_names)}\n",
    "all_labels = [(label.numpy(), label_mapping[label.numpy()]) for _, label in train_dataset]\n",
    "unique_labels = {(label.numpy(), label_mapping[label.numpy()]) for _, label in train_dataset}\n",
    "dataset = pd.DataFrame(sorted(unique_labels), columns=[\"Label Number\", \"Label Name\"],index=None)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('lables.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = loadmat(\"imagelabels.mat\")\n",
    "print(data_set.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabeldataSet = data_set['labels'][0]\n",
    "a = [x for x in LabeldataSet if x == 85]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "repeat = 1\n",
    "plot_count = 1\n",
    "CurrentclassNum = LabeldataSet[0]\n",
    "for i, image in enumerate(os.listdir('102flowers')):\n",
    "    if repeat <= 5 and CurrentclassNum == LabeldataSet[i]:\n",
    "        plt.subplot(4, 5, plot_count)\n",
    "        image_path = os.path.join('102flowers',image)\n",
    "        imageForShow = Image.open(image_path)\n",
    "        plt.imshow(imageForShow)\n",
    "        plt.title(f\"Class: {LabeldataSet[i]}\")\n",
    "        plt.axis(\"off\")\n",
    "        plot_count += 1\n",
    "\n",
    "    repeat += 1\n",
    "\n",
    "    if CurrentclassNum != LabeldataSet[i]:\n",
    "        repeat = 1\n",
    "        CurrentclassNum = LabeldataSet[i]\n",
    "\n",
    "    if plot_count > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lables_name = pd.read_csv('lables.csv')\n",
    "lables_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(lables_name['Label Name'][77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentclassNum = LabeldataSet[0]\n",
    "\n",
    "for i, image in enumerate(os.listdir('102flowers')):\n",
    "    if CurrentclassNum == LabeldataSet[i]:\n",
    "        if not os.path.isdir(lables_name['Label Name'][CurrentclassNum]):\n",
    "            image_path = os.path.join(lables_name['Label Name'][CurrentclassNum])\n",
    "            os.makedirs('image_path')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_images_by_labels(labels, images, target_labels={101, 102}):\n",
    "    \"\"\"\n",
    "    فیلتر کردن تصاویر بر اساس لیبل‌های مشخص شده (۱۰۱ و ۱۰۲)\n",
    "    :param labels: لیست لیبل‌ها\n",
    "    :param images: لیست تصاویر\n",
    "    :param target_labels: مجموعه‌ای از لیبل‌های مورد نظر\n",
    "    :return: لیست جدید شامل تصاویر با لیبل‌های مشخص‌شده\n",
    "    \"\"\"\n",
    "    unseen = [[img,lbl] for lbl, img in zip(labels, images) if lbl in target_labels]\n",
    "    seen = [img for lbl, img in zip(labels, images) if lbl not in target_labels]\n",
    "    return unseen, seen\n",
    "\n",
    "# مثال استفاده:\n",
    "labels = [100, 101, 102, 103, 101, 105, 102]\n",
    "images = ['img1', 'img2', 'img3', 'img4', 'img5', 'img6', 'img7']\n",
    "\n",
    "unseen,seen  = filter_images_by_labels(labels, images)\n",
    "print(unseen)  # خروجی: ['img2', 'img3', 'img5', 'img7']\n",
    "print(seen) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.arange(12) + 1\n",
    "print(arr)\n",
    "mask = np.ones(len(arr), dtype=bool)\n",
    "print(mask)\n",
    "mask[[0,2,4]] = False\n",
    "print(mask)\n",
    "result = arr[mask,...]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "images = os.listdir('102flowers')\n",
    "text_lables = pd.read_csv('Oxford-102_Flower_dataset_labels.csv')\n",
    "matlabels = loadmat('imagelabels.mat')\n",
    "labels = matlabels['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenth = len(labels)\n",
    "print(lenth-90)\n",
    "print(lenth)\n",
    "labels[lenth-90:lenth+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_labels = [ 7,  7,  7,  7,  7,  6,  6,  6,  6,  6,  6,  6, 93, 93, 93, 93, 93,\n",
    "       93, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57,\n",
    "       57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57,\n",
    "       62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
    "       62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62,\n",
    "       62, 62, 62, 62, 62]\n",
    "\n",
    "def get_last_unique_labels1(labels, n=2):\n",
    "    unique_labels = sorted(set(labels))  # حذف مقادیر تکراری و مرتب‌سازی\n",
    "    return unique_labels[-n:]\n",
    "\n",
    "def get_last_unique_labels2(labels, n=2):\n",
    "    unique_labels = []\n",
    "    for label in reversed(labels):  # پیمایش لیست از انتها\n",
    "        if label not in unique_labels:\n",
    "            unique_labels.append(label)\n",
    "        if len(unique_labels) == n:\n",
    "            break\n",
    "    return list(reversed(unique_labels))  # بازگرداندن ترتیب اصلی\n",
    "\n",
    "last_unique_labels = get_last_unique_labels1(a_labels)\n",
    "print(last_unique_labels)\n",
    "\n",
    "last_unique_labels = get_last_unique_labels2(a_labels)\n",
    "print(last_unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labels_and_images(labels, images, target_labels={57, 62}):\n",
    "    \"\"\"\n",
    "    جداسازی لیبل‌های 57 و 62 از بقیه لیبل‌ها همراه با تصاویر معادلشان\n",
    "    :param labels: لیست لیبل‌ها\n",
    "    :param images: لیست تصاویر\n",
    "    :param target_labels: لیبل‌هایی که باید جدا شوند\n",
    "    :return: (لیبل‌های 7، 6، 93 و تصاویر معادلشان), (لیبل‌های 57، 62 و تصاویر معادلشان)\n",
    "    \"\"\"\n",
    "    group1_labels, group1_images = [], []  # برای لیبل‌های 7، 6، 93\n",
    "    group2_labels, group2_images = [], []  # برای لیبل‌های 57، 62\n",
    "\n",
    "    for lbl, img in zip(labels, images):\n",
    "        if lbl in target_labels:\n",
    "            group2_labels.append(lbl)\n",
    "            group2_images.append(img)\n",
    "        else:\n",
    "            group1_labels.append(lbl)\n",
    "            group1_images.append(img)\n",
    "\n",
    "    return (group1_labels, group1_images), (group2_labels, group2_images)\n",
    "\n",
    "# نمونه داده‌ها\n",
    "a_labels = [7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 93, 93, 93, 93, 93, 93, \n",
    "            57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, \n",
    "            57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, \n",
    "            62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, \n",
    "            62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, \n",
    "            62, 62, 62, 62, 62, 62, 62, 62]\n",
    "\n",
    "a_images = [f\"img{i}\" for i in range(len(a_labels))]  # شبیه‌سازی لیست تصاویر\n",
    "\n",
    "# اجرای تابع\n",
    "(group1, images1), (group2, images2) = split_labels_and_images(a_labels, a_images)\n",
    "\n",
    "# نمایش نتایج\n",
    "print(\"لیبل‌های 7، 6، 93:\", group1)\n",
    "print(\"تصاویر معادل آن‌ها:\", images1)\n",
    "print(\"لیبل‌های 57 و 62:\", group2)\n",
    "print(\"تصاویر معادل آن‌ها:\", images2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[1,2,3,4,5,6]\n",
    "a = a + [9]\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_unique_labels(labels, n=2):\n",
    "    unique_labels = []\n",
    "    for label in reversed(labels):\n",
    "        if label not in unique_labels:\n",
    "            unique_labels.append(label)\n",
    "        if len(unique_labels) == n:\n",
    "            break\n",
    "    return list(reversed(unique_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_57_62_labels(images, labels):\n",
    "    unseen_label = get_last_unique_labels(labels)\n",
    "    unseen_images = []\n",
    "    unseen_images = [[img, lbl] for lbl, img in zip(labels, images) if lbl in unseen_label]\n",
    "    seen_images = [img for lbl, img in zip(labels, images) if lbl not in unseen_label]\n",
    "    return seen_images , unseen_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "# for i in tqdm(range(50)):\n",
    "#     sleep(0.25)\n",
    "\n",
    "a_images = [f\"img{i}\" for i in range(50)] \n",
    "for i,j in tqdm(enumerate(a_images), total=len(a_images)):\n",
    "    sleep(0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# داده‌های نمونه\n",
    "data = [\n",
    "    [1.0, 2.0],  # ویژگی‌ها\n",
    "    [3.0, 4.0],\n",
    "    [5.0, 6.0]\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    0,  # برچسب‌ها\n",
    "    1,\n",
    "    0\n",
    "]\n",
    "\n",
    "# تبدیل داده‌ها به Dataset\n",
    "class CustomDataLoader(tf.data.Dataset):\n",
    "    def __new__(cls):\n",
    "        return tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "\n",
    "# بارگذاری داده‌ها\n",
    "dataset = CustomDataLoader()\n",
    "\n",
    "# ایجاد DataLoader برای بچ‌های داده‌ها\n",
    "batch_size = 2\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "# پیمایش داده‌ها\n",
    "for batch_data, batch_labels in dataset:\n",
    "    print(\"Data:\", batch_data.numpy())\n",
    "    print(\"Labels:\", batch_labels.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataLoader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, labels, batch_size):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(data))  # ایندکس‌ها برای پیمایش داده‌ها\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        تعداد بچ‌ها در یک اپوک را برمی‌گرداند.\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.data) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        یک بچ از داده‌ها را با توجه به ایندکس دریافت می‌کند.\n",
    "        \"\"\"\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_data = [self.data[i] for i in batch_indexes]\n",
    "        batch_labels = [self.labels[i] for i in batch_indexes]\n",
    "        \n",
    "        # تبدیل داده‌ها به قالب TensorFlow\n",
    "        return np.array(batch_data), np.array(batch_labels)\n",
    "\n",
    "    def _generate_batch(self, batch_indexes):\n",
    "        \"\"\"\n",
    "        یک متد خصوصی برای تولید بچ‌ها.\n",
    "        \"\"\"\n",
    "        batch_data = [self.data[i] for i in batch_indexes]\n",
    "        batch_labels = [self.labels[i] for i in batch_indexes]\n",
    "        return np.array(batch_data), np.array(batch_labels)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        این متد بعد از هر اپوک برای به هم زدن داده‌ها فراخوانی می‌شود.\n",
    "        \"\"\"\n",
    "        # به هم زدن ایندکس‌ها برای جلوگیری از ترتیب ثابت\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "\n",
    "# داده‌های نمونه\n",
    "data = np.random.random((100, 10))  # 100 نمونه، 10 ویژگی\n",
    "labels = np.random.randint(0, 2, 100)  # 100 برچسب (0 یا 1)\n",
    "\n",
    "# پارامترها\n",
    "batch_size = 16\n",
    "\n",
    "# ایجاد DataLoader\n",
    "data_loader = CustomDataLoader(data, labels, batch_size)\n",
    "\n",
    "# پیمایش داده‌ها در بچ‌ها\n",
    "for batch_data, batch_labels in data_loader:\n",
    "    print(\"Batch Data Shape:\", batch_data.shape)\n",
    "    print(\"Batch Labels Shape:\", batch_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataLoader(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, labels, batch_size, shuffle=True):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(data))  # ایندکس‌ها برای پیمایش داده‌ها\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):      \n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if index >= self.__len__():\n",
    "            raise IndexError(\"Batch index out of range\")    \n",
    "        \n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        return self._generate_batch(batch_indexes)\n",
    "    \n",
    "    def _generate_batch(self, batch_indices):\n",
    "        batch_data = [self.data[i] for i in batch_indices]\n",
    "        batch_labels = [self.labels[i] for i in batch_indices]\n",
    "        return np.array(batch_data), np.array(batch_labels)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.random((100, 2))  # 100 نمونه، 10 ویژگی\n",
    "labels = np.random.randint(0, 2, 100)  # 100 برچسب (0 یا 1)\n",
    "batch_size = 16\n",
    "data_loader = CustomDataLoader(data, labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for batch_data, batch_labels in data_loader:\n",
    "    if(i == 6):\n",
    "        print(\"Batch Data Shape:\", batch_data)\n",
    "    #print(\"Batch Labels Shape:\", batch_labels)\n",
    "    print(i, batch_data.shape)\n",
    "    i +=1\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered_indices = [i for i in range(len(trainset)) if trainset.targets[i] != 9]\n",
    "test_filtered_indices = [i for i in range(len(testset)) if testset.targets[i] != 9]\n",
    "\n",
    "trainset_filtered = Subset(trainset, train_filtered_indices)\n",
    "testset_filtered = Subset(testset, test_filtered_indices)\n",
    "\n",
    "train_loader = DataLoader(trainset_filtered, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(testset_filtered, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "labels = np.random.randint(1,10,20)\n",
    "current_label = 9\n",
    "neg_label = np.random.choice(labels[labels != current_label])\n",
    "neg_idx = np.random.choice(np.where(labels == neg_label)[0])\n",
    "\n",
    "print(neg_label, neg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 12, 14])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(labels == neg_label)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
